{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import modeling\n",
    "import helpers\n",
    "import plotting\n",
    "import scienceplots\n",
    "plt.style.use(['science','no-latex'])\n",
    "# plt.style.use(['science','ieee','no-latex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "    all_data = data_dict['data']\n",
    "    meta_data = data_dict['meta_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_inds = (meta_data['Condition'] == 'V1-V1') & (meta_data['Cluster'] == 0)\n",
    "this_data = helpers.slice_data(all_data, meta_data, 'V1-V1', exp=[1,2], cluster=0)\n",
    "num_subject = np.sum(subject_inds)\n",
    "\n",
    "alpha_bounds = [1e-6, 1]\n",
    "beta_bounds = [1e-6, 10]\n",
    "concentration_bounds = [-2, 1]\n",
    "epsilon_bounds = [-2, 0]\n",
    "bounds = [alpha_bounds, beta_bounds, concentration_bounds, epsilon_bounds] \n",
    "param_names = ['alpha_2', 'beta_2', 'concentration_2', 'v_repeat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward structured model without meta-learning (fitted to Blocks 1-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_model = 'option_model'\n",
    "structure = 'backward'\n",
    "meta_learning = False\n",
    "\n",
    "best_llh_all = np.zeros(num_subject)\n",
    "best_params_all = np.zeros((num_subject, len(param_names)))\n",
    "\n",
    "D = helpers.get_model_fit_data(this_data, num_block=6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = []\n",
    "       \n",
    "    for i in range(num_subject):\n",
    "        inputs.append((this_model, D[D[:,0]==i,:], structure, i, bounds, meta_learning))\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_worker, inputs)\n",
    "\n",
    "    for i, best_params, best_llh in results:\n",
    "        best_params_all[i, :], best_llh_all[i] = best_params, best_llh\n",
    "\n",
    "np.save('fitting_results/'+structure+'_no_meta_params.npy', best_params_all)\n",
    "np.save('fitting_results/'+structure+'_no_meta_llh.npy', best_llh_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward structured model (fitted to Blocks 1-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_model = 'option_model'\n",
    "structure = 'backward'\n",
    "meta_learning = True\n",
    "\n",
    "best_llh_all = np.zeros(num_subject)\n",
    "best_params_all = np.zeros((num_subject, len(param_names)))\n",
    "\n",
    "D = helpers.get_model_fit_data(this_data, num_block=6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = []\n",
    "       \n",
    "    for i in range(num_subject):\n",
    "        if subject_inds[i]:\n",
    "            inputs.append((this_model, D[D[:,0]==i,:], structure, i, bounds, meta_learning))\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_worker, inputs)\n",
    "\n",
    "    for i, best_params, best_llh in results:\n",
    "        best_params_all[i, :], best_llh_all[i] = best_params, best_llh\n",
    "\n",
    "np.save('fitting_results/'+structure+'_blocks1-6_params.npy', best_params_all)\n",
    "np.save('fitting_results/'+structure+'_blocks1-6_llh.npy', best_llh_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fitted parameters\n",
    "best_params_all_backward_no_meta = np.load('fitting_results/backward_no_meta_params.npy')\n",
    "best_params_all_backward_first6 = np.load('fitting_results/backward_blocks1-6_params.npy')\n",
    "best_params_all_forward = np.load('fitting_results/forward_params.npy')\n",
    "best_params_all_backward = np.load('fitting_results/backward_params.npy')\n",
    "\n",
    "best_llh_all_backward_no_meta = np.load('fitting_results/backward_no_meta_llh.npy')\n",
    "best_llh_all_backward_first6 = np.load('fitting_results/backward_blocks1-6_llh.npy')\n",
    "best_llh_all_forward = np.load('fitting_results/forward_llh.npy')\n",
    "best_llh_all_backward = np.load('fitting_results/backward_llh.npy')\n",
    "\n",
    "niters_sim = 3\n",
    "this_model = 'option_model'\n",
    "cluster = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_backward_no_meta = -2*best_llh_all_backward_no_meta + 2*4\n",
    "aic_backward_first6 = -2*best_llh_all_backward_first6 + 2*5\n",
    "llh_mean = (best_llh_all_backward_no_meta + best_llh_all_backward_first6) / 2\n",
    "condition = 'All'\n",
    "plt.figure(figsize=(5,3))\n",
    "inds = (meta_data['Cluster']==cluster) & (meta_data['Condition']=='V1-V1')\n",
    "this_llh_mean = llh_mean[inds]\n",
    "noise = np.random.normal(0, 0.1, np.sum(inds))\n",
    "m1_fit_metric = (best_llh_all_backward_no_meta[inds] - this_llh_mean)\n",
    "m2_fit_metric = (best_llh_all_backward_first6[inds] - this_llh_mean)\n",
    "t_stat, p_value = stats.ttest_rel(m1_fit_metric, m2_fit_metric, alternative='less')\n",
    "plt.plot(np.ones(np.sum(inds))+noise, m1_fit_metric, '.', mew=0, ms=5, color='lightcoral', alpha=0.2)\n",
    "plt.plot(np.ones(np.sum(inds))*2+noise, m2_fit_metric, '.', mew=0, ms=5, color='cornflowerblue', alpha=0.2)\n",
    "plt.boxplot([m1_fit_metric, m2_fit_metric], sym='', widths=0.3, patch_artist=True, boxprops=dict(facecolor='none', color='black'), whiskerprops=dict(color='black'), medianprops=dict(color='black'), capprops=dict(color='black'))\n",
    "plt.text(1.25, max(max(m1_fit_metric), max(m2_fit_metric))-10, f'p = {p_value:.2e}', horizontalalignment='left', verticalalignment='top')\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.xticks([1,2], ['No meta-learning', 'Meta-learning'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Log-likelihood (normalized)')\n",
    "plt.title(f'{condition}, Cluster {cluster}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All (first 6 blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_inds = (meta_data['Cluster'] == cluster) & (meta_data['Condition'] == 'V1-V1')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = []\n",
    "    inputs_2 = []\n",
    "    for i in range(best_params_all_backward_first6[subject_inds].shape[0]):\n",
    "        params = best_params_all_backward_no_meta[subject_inds][i,:]\n",
    "        inputs.append((this_model, i, niters_sim, params, 'V1-V1', 'backward', False))\n",
    "        params = best_params_all_backward_first6[subject_inds][i,:]\n",
    "        inputs_2.append((this_model, i, niters_sim, params, 'V1-V1', 'backward', True))\n",
    "        \n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_simulator, inputs)\n",
    "\n",
    "    data_sim_backward_no_meta = {}\n",
    "    for _, this_data in results:\n",
    "        data_sim_backward_no_meta = helpers.concatenate_data(this_data, data_sim_backward_no_meta)\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_simulator, inputs_2)\n",
    "\n",
    "    data_sim_backward = {}\n",
    "    for _, this_data in results:\n",
    "        data_sim_backward = helpers.concatenate_data(this_data, data_sim_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_data = helpers.slice_data(all_data, meta_data, 'V1-V1', exp=[1,2], cluster=cluster)\n",
    "plotting.plot_validation_n_presses(this_data, data_sim_backward_no_meta, data_sim_backward, 'All', cluster, nblocks=6, m1='No meta-learning', m2='Meta-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotting.plot_validation_error_types(this_data, data_sim_backward_no_meta, data_sim_backward, 'All', cluster, nblocks=6, m1='No meta-learning', m2='Meta-learning', save_vector=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_validation_PTS(data_sim_backward, 'Backward', ntrials=5, cond='V1-V1', save_vector=True, pallette=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_model = 'option_model'\n",
    "structure = 'backward'\n",
    "meta_learning = True\n",
    "cluster = 0\n",
    "condition = 'All'\n",
    "best_params_all_backward_first6 = np.load('fitting_results/backward_blocks1-6_params.npy')\n",
    "fitted_params = best_params_all_backward_first6[(meta_data['Cluster']==cluster) & (meta_data['Condition']=='V1-V1')]\n",
    "num_subject = fitted_params.shape[0]\n",
    "\n",
    "best_llh_all = np.zeros(num_subject)\n",
    "best_params_all = np.zeros((num_subject, len(param_names)))\n",
    "\n",
    "all_sim_data = {}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = []\n",
    "       \n",
    "    for i in range(num_subject):\n",
    "        inputs.append((this_model, i, 1, fitted_params[i], 'V1-V1', structure, meta_learning))\n",
    "        \n",
    "        \n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_simulator, inputs)\n",
    "        \n",
    "    inputs = []\n",
    "        \n",
    "    for i, this_data in results:\n",
    "        all_sim_data = helpers.concatenate_data(this_data, all_sim_data)\n",
    "        D = helpers.get_model_fit_data(this_data, num_block=6)  \n",
    "        inputs.append((this_model, D, structure, i, bounds, meta_learning))\n",
    "\n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_worker, inputs)\n",
    "\n",
    "    for i, best_params, best_llh in results:\n",
    "        best_params_all[i, :], best_llh_all[i] = best_params, best_llh\n",
    "\n",
    "np.save(f'fitting_results/paramrec_{structure}_{condition}_cluster{cluster}_params.npy', best_params_all)\n",
    "np.save(f'fitting_results/paramrec_{structure}_{condition}_cluster{cluster}_llh.npy', best_llh_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "for p in range(len(bounds)):\n",
    "    for q in range(len(bounds)):\n",
    "        ax = plt.subplot(len(bounds), len(bounds), p*len(bounds)+q+1)\n",
    "        p_bounds = bounds[p].copy()\n",
    "        q_bounds = bounds[q].copy()\n",
    "\n",
    "        values_p = fitted_params[:,p]\n",
    "        values_q = best_params_all[:,q]\n",
    "        if 'concentration' or 'v_repeat' in param_names[p]:\n",
    "            p_bounds[0] = 10**p_bounds[0]\n",
    "            p_bounds[1] = 10**p_bounds[1]\n",
    "            values_p = 10**values_p\n",
    "        if 'concentration' or 'v_repeat' in param_names[q]:\n",
    "            q_bounds[0] = 10**q_bounds[0]\n",
    "            q_bounds[1] = 10**q_bounds[1]\n",
    "            values_q = 10**values_q\n",
    "        color = 'r' if p == q else 'k'\n",
    "        plt.plot(values_p, values_q, '.', color=color)\n",
    "        plt.plot([p_bounds[0],p_bounds[1]], [q_bounds[0], q_bounds[1]])\n",
    "        plt.xlim(p_bounds)\n",
    "        plt.ylim(q_bounds)\n",
    "        plt.xlabel(f'True {param_names[p]}')\n",
    "        plt.ylabel(f'Recovered {param_names[q]}')\n",
    "        ax.set_box_aspect(1)\n",
    "\n",
    "plt.suptitle(f'Parameter recovery for {this_model}, Cluster {cluster}, {condition}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sim_data_rec = {}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = []\n",
    "       \n",
    "    for i in range(num_subject):\n",
    "        inputs.append((this_model, i, 1, fitted_params[i], 'V1-V1', structure, meta_learning))\n",
    "        \n",
    "        \n",
    "    with Pool() as p:\n",
    "        results = p.map(modeling.parallel_simulator, inputs)\n",
    "        \n",
    "    inputs = []\n",
    "        \n",
    "    for i, this_data in results:\n",
    "        all_sim_data_rec = helpers.concatenate_data(this_data, all_sim_data_rec)\n",
    "        \n",
    "plotting.plot_validation_n_presses(all_sim_data, all_sim_data_rec, all_sim_data_rec, 'All', 0, nblocks=6, m1='Meta-learning', m2='Meta-learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_validation_error_types(all_sim_data, all_sim_data_rec, all_sim_data_rec, 'All', cluster, nblocks=6, m1='Meta-learning', m2='Meta-learning')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
